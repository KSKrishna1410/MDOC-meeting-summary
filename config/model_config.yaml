# Model Configuration for LLM Integration
models:
  default:
    provider: "gemini"  # Using Gemini via LiteLLM
    model_name: "gemini/gemini-1.5-pro"
    temperature: 0.7
    max_tokens: 2048
    top_p: 0.95
  
  gemini:
    api_key: "${GEMINI_API_KEY}"
    model_name: "gemini/gemini-1.5-pro"

api_settings:
  timeout: 30
  max_retries: 3
  retry_delay: 1

generation_params:
  default_temperature: 0.7
  creative_temperature: 0.9
  precise_temperature: 0.3

